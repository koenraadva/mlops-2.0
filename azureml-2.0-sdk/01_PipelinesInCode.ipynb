{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, you will need to create an environment to run these cells. I have done so using a \"pyenv\", follow the instructions on the internet to do so.\n",
        "This allows me to simply install the necessary packages and then run this notebook file using the right kernel (selected here in the top right corner: \"mlops (Python 3.10.10)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1683701622980
        }
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import load_component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "## Either get environment variables, or a fallback name, which is the second parameter.\n",
        "## Currently, fill in the fallback values. Later on, we will make sure to work with Environment values. So we're already preparing for it in here!\n",
        "workspace_name = os.environ.get('WORKSPACE', 'mlops-nathan')\n",
        "subscription_id = os.environ.get('SUBSCRIPTION_ID', '7c50f9c3-289b-4ae0-a075-08784b3b9042')\n",
        "resource_group = os.environ.get('RESOURCE_GROUP', 'mlops')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1683701623388
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Because we are running this in an interactive notebook; we can use the InteractiveBrowserCredential\n",
        "# This allows us to open a browser window and login there\n",
        "credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1683701624170
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ml_client = MLClient(\n",
        "    credential, subscription_id, resource_group, workspace_name\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare a Virtual PC if needed\n",
        "\n",
        "If we need to get a CPU cluster, or a single-node machine, we can again create on using the SDK...\n",
        "\n",
        "But we can also just create one in the Portal and then fetch it from here, which might be the safest option to be cheaper.\n",
        "\n",
        "When you're configuring it in the Portal, select the \"STANDARD_A4M_V2\" one to have enough RAM, CPU Power and Storage to run the scripts. The cheapest one is not powerful enough ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1683701692502
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You already have a machine named cpu-automated-test, we'll reuse it as is.\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# STANDARD_A4M_V2\n",
        "cpu_compute_target = \"cpu-automated-test\"\n",
        "\n",
        "\n",
        "# let's see if the compute target already exists\n",
        "cpu_machine = ml_client.compute.get(cpu_compute_target)\n",
        "print(\n",
        "    f\"You already have a machine named {cpu_compute_target}, we'll reuse it as is.\"\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also need to setup the Environment to use for our Data Preparation scripts.\n",
        "For this one, I call it \"aml-Pillow\", because we are mostly going to use the \"Pillow\" library to do the image processing.\n",
        "\n",
        "It requires a \"components/dataprep/conda.yaml\" file, which I will show you where to find and copy just now. It's in the \"azureml-2.0-automation/components/dataprep\" directory, because it was later used in there, and not copied, just cut... Sorry!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1683701627246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment with name aml-Pillow is registered to workspace, the environment version is 2\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "\n",
        "custom_env_name = \"aml-Pillow\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for Image Processing (with Pillow)\",\n",
        "    tags={\"Pillow\": \"0.0.1\"},\n",
        "    conda_file=os.path.join(\"components\", \"dataprep\", \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1683701627365
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1683701627464
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_prep_src_dir = \"./components/dataprep\"\n",
        "os.makedirs(data_prep_src_dir, exist_ok=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1683556923402
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./components/dataprep/dataprep.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {data_prep_src_dir}/dataprep.py\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--output_data\", type=str, help=\"path to output data\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    print(\"input data:\", args.data)\n",
        "    print(\"output folder:\", args.output_data)\n",
        "\n",
        "    output_dir = args.output_data\n",
        "    size = (64, 64) # Later we can also pass this as a property\n",
        "\n",
        "\n",
        "    for file in glob(args.data + \"/*.jpg\"):\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(size)\n",
        "\n",
        "        # Save the resized image to the output directory\n",
        "        output_file = os.path.join(output_dir, os.path.basename(file))\n",
        "        img_resized.save(output_file)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1683704215484
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "# This registers a component with the name \"data_prep_image_resize\"\n",
        "# Which can then be used in the Pipeline editor of the Azure Portal\n",
        "data_prep_component = command(\n",
        "    name=\"data_prep_image_resize\",\n",
        "    display_name=\"Data preparation, Image Resizing\",\n",
        "    description=\"Reads a data asset of images and preprocesses them by resizing them to 64 to 64.\",\n",
        "    inputs={\n",
        "        \"data\": Input(type=\"uri_folder\"),\n",
        "    },\n",
        "    outputs={\n",
        "        \"output_data\": Output(type=\"uri_folder\", mode=\"rw_mount\")\n",
        "    },\n",
        "    # The source folder of the component\n",
        "    code=data_prep_src_dir,\n",
        "    command=\"\"\"python dataprep.py \\\n",
        "            --data ${{inputs.data}} \\\n",
        "            --output_data ${{outputs.output_data}} \\\n",
        "            \"\"\",\n",
        "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1683704292690
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component data_prep_image_resize with Version 2023-06-12-16-11-34-1369384 is registered\n"
          ]
        }
      ],
      "source": [
        "# Now we register the component to the workspace\n",
        "data_prep_component = ml_client.create_or_update(data_prep_component.component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {data_prep_component.name} with Version {data_prep_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that it's registered, it's possible to start using it in the Pipelines.\n",
        "\n",
        "Because it's fun to do it from the SDK, we can show you that. But first, check out the recording to see how it works in the Azure Portal too..\n",
        "\n",
        "As you might've noticed in the recording, the designer is OK for a bit, but we can't really customize everything in there... That's why we want to take it a step further and automate it from the SDK in here..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1683707979201
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1683709398166
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=cpu_compute_target,\n",
        "    description=\"Custom data_prep pipeline\",\n",
        ")\n",
        "def animal_images_preprocessing_pipeline(\n",
        "    input_version: str, # Currently we don't use these version numbers, but we will use them later on.\n",
        "    output_version: str,\n",
        "):\n",
        "    # using data_prep_function like a python call with its own inputs\n",
        "    # These are the animals with the version name as a second item in the tuple\n",
        "    animals = [\n",
        "        ('pandas', \"1\"),\n",
        "        ('cats', \"1\"),\n",
        "        ('dogs', \"1\")\n",
        "    ] # They are hardcoded in here, because we should give them from another component otherwise.\n",
        "    \n",
        "    jobs = {}\n",
        "    for animal in animals:\n",
        "\n",
        "        data_prep_job = data_prep_component(\n",
        "            data=Input(\n",
        "                type=\"uri_folder\",\n",
        "                path=f\"azureml:{animal[0]}:{animal[1]}\" # There was a typo here that I fixed\n",
        "            ),\n",
        "        )\n",
        "        \n",
        "        output_name = animal[0] + \"_resized\"\n",
        "        output_path = \"azureml://subscriptions/7c50f9c3-289b-4ae0-a075-08784b3b9042/resourcegroups/mlops/workspaces/mlops-nathan/datastores/workspaceblobstore/paths/processed_animals/\" + animal[0]\n",
        "\n",
        "        data_prep_job.outputs.output_data = Output(\n",
        "            type=\"uri_folder\",\n",
        "            path=output_path,\n",
        "            name=output_name,\n",
        "            mode=\"rw_mount\"\n",
        "        )\n",
        "\n",
        "        jobs[animal[0]] = data_prep_job\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        k: v.outputs.output_data for k,v in jobs.items()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1683709400871
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "pipeline = animal_images_preprocessing_pipeline()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By executing the cell below, you're scripting something to make the Data Prep Pipeline run. It will use the \"dataprep.py\" script, which is located in the \"components/dataprep\" directory.\n",
        "\n",
        "It opened up your browser where you can see three different parallell runs. They will all take one of the datasets, and process it one by one, then upload it to the Datastore under the \"dogs_resized\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1683709441303
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import webbrowser\n",
        "\n",
        "# submit the pipeline job\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    # Project's name\n",
        "    experiment_name=\"image_preprocessing_pipeline\",\n",
        ")\n",
        "# open the pipeline in web browser\n",
        "webbrowser.open(pipeline_job.studio_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train test split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that they are all resized in the cloud, we can try to split them up into a train and test set as well.\n",
        "\n",
        "We will repeat the steps:\n",
        "- Create the Component script\n",
        "- Register the Component in Azure\n",
        "- Use the Component in a Pipeline\n",
        "- Run the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./components/dataprep/traintestsplit.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {data_prep_src_dir}/traintestsplit.py\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "from glob import glob\n",
        "import math\n",
        "import random\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    SEED = 42\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--datasets\", type=str, nargs=\"+\", help=\"All the datasets to combine\")\n",
        "    parser.add_argument(\"--training_data_output\", type=str, help=\"path to training output data\")\n",
        "    parser.add_argument(\"--testing_data_output\", type=str, help=\"path to testing output data\")\n",
        "    parser.add_argument(\"--split_size\", type=int, help=\"Percentage to use as Testing data\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    print(\"input data:\", args.datasets)\n",
        "    print(\"Training folder:\", args.training_data_output)\n",
        "    print(\"Testing folder:\", args.testing_data_output)\n",
        "    print(\"Split size:\", args.split_size)\n",
        "\n",
        "    train_test_split_factor = args.split_size / 100 # Alias\n",
        "    datasets = args.datasets\n",
        "\n",
        "    training_datapaths = []\n",
        "    testing_datapaths = []\n",
        "\n",
        "\n",
        "    for dataset in datasets:\n",
        "        animal_images = glob(dataset + \"/*.jpg\")\n",
        "        print(f\"Found {len(animal_images)} images for {dataset}\")\n",
        "\n",
        "        ## Concatenate the names for the animal_name and the img_path. Don't put a / between, because the img_path already contains that\n",
        "        ## animal_images = [(default_datastore, f'processed_animals/{animal_name}{img_path}') for img_path in animal_images] # Make sure the paths are actual DataPaths\n",
        "    \n",
        "        random.seed(SEED) # Use the same random seed as I use and defined in the earlier cells\n",
        "        random.shuffle(animal_images) # Shuffle the data so it's randomized\n",
        "\n",
        "        ## Testing images\n",
        "        amount_of_test_images = math.ceil(len(animal_images) * train_test_split_factor) # Get a small percentage of testing images\n",
        "\n",
        "        animal_test_images = animal_images[:amount_of_test_images]\n",
        "        animal_training_images = animal_images[amount_of_test_images:]\n",
        "\n",
        "        # Add them all to the other ones\n",
        "        testing_datapaths.extend(animal_test_images)\n",
        "        training_datapaths.extend(animal_training_images)\n",
        "\n",
        "        print(testing_datapaths[:5])\n",
        "\n",
        "        # Write the data to the output\n",
        "        for img in animal_test_images:\n",
        "            # Open the img, which is a string filepath, then save it to the args.testing_data_output directory\n",
        "            with open(img, \"rb\") as f:\n",
        "                with open(os.path.join(args.testing_data_output, os.path.basename(img)), \"wb\") as f2:\n",
        "                    f2.write(f.read())\n",
        "\n",
        "        for img in animal_training_images:\n",
        "            # Open the img, which is a string filepath, then save it to the args.testing_data_output directory\n",
        "            with open(img, \"rb\") as f:\n",
        "                with open(os.path.join(args.training_data_output, os.path.basename(img)), \"wb\") as f2:\n",
        "                    f2.write(f.read())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "data_split_component = command(\n",
        "    name=\"data_split\",\n",
        "    display_name=\"Data Splitting to Train and Test\",\n",
        "    description=\"Reads a data asset of images and combines them into a training and testing dataset\",\n",
        "    # We want to give the datasets as a dynamic input ...\n",
        "   inputs={\n",
        "        \"animal_1\": Input(type=\"uri_folder\"),\n",
        "        \"animal_2\": Input(type=\"uri_folder\"),\n",
        "        \"animal_3\": Input(type=\"uri_folder\"),\n",
        "        \"train_test_split_factor\": Input(type=\"number\") # The percentage of the data to use as testing data, always a positive value\n",
        "    },\n",
        "    # ... and take the outputs as a dynamic output to override the training and testset locations.\n",
        "    outputs={\n",
        "        \"training_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "        \"testing_data\": Output(type=\"uri_folder\", mode=\"rw_mount\")\n",
        "    },\n",
        "    # The source folder of the component\n",
        "    code=data_prep_src_dir,\n",
        "    command=\"\"\"python traintestsplit.py \\\n",
        "            --datasets ${{inputs.animal_1}} ${{inputs.animal_2}} ${{inputs.animal_3}} \\\n",
        "            --training_data ${{outputs.training_data}} \\\n",
        "            --testing_data ${{outputs.testing_data}} \\\n",
        "            --split_size ${{inputs.train_test_split_factor}}\n",
        "            \"\"\",\n",
        "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component data_split with Version 2023-06-12-16-11-43-4931660 is registered\n"
          ]
        }
      ],
      "source": [
        "# Now we register the component to the workspace\n",
        "data_split_component = ml_client.create_or_update(data_split_component.component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {data_split_component.name} with Version {data_split_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=cpu_compute_target,\n",
        "    description=\"Custom data_prep pipeline\",\n",
        ")\n",
        "def animal_images_traintest_split_pipeline(\n",
        "    train_test_split: int, # Currently we don't use these version numbers, but we will use them later on.\n",
        "    animal_1: Input,\n",
        "    animal_2: Input,\n",
        "    animal_3: Input,\n",
        "):\n",
        "    # using data_prep_function like a python call with its own inputs\n",
        "    # These are the animals with the version name as a second item in the tuple\n",
        "\n",
        "    # Combining arguments starting with \"animals_\" into a dictionary\n",
        "    animals_args = {k: v for k, v in locals().items() if k.startswith(\"animals_\")}\n",
        "\n",
        "    # Create a component instance by calling the component factory\n",
        "    data_split_job = data_split_component(\n",
        "            animal_1=animal_1,\n",
        "            animal_2=animal_2,\n",
        "            animal_3=animal_3,\n",
        "            train_test_split_factor=train_test_split\n",
        "        )\n",
        "    \n",
        "    # Override the training data output and testing data output to a file named \"trainingdata\" and \"testingdata\n",
        "    data_split_job.outputs.training_data = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"training_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "    data_split_job.outputs.testing_data = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"testing_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        \"training_data\": data_split_job.outputs.training_data,\n",
        "        \"testing_data\": data_split_job.outputs.testing_data\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'animal_1': {'type': 'uri_folder', 'path': 'azureml:pandas_resized:1'}, 'animal_2': {'type': 'uri_folder', 'path': 'azureml:cats_resized:1'}, 'animal_3': {'type': 'uri_folder', 'path': 'azureml:dogs_resized:1'}}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "version = \"1\" # We can choose which version of the resized_pandas it will use\n",
        "animals = [\"pandas\", \"cats\", \"dogs\"]\n",
        "\n",
        "# Apparently, we made a small mistake in the naming conventions, but we will ignore that for now, we can fix it later...\n",
        "animals_datasets = {\n",
        "    f\"animal_{i+1}\": Input(type=\"uri_folder\", path=f\"azureml:{animal}_resized:{version}\")\n",
        "    for i, animal in enumerate(animals)\n",
        "}\n",
        "\n",
        "print(animals_datasets)\n",
        "\n",
        "train_test_pipeline = animal_images_traintest_split_pipeline(\n",
        "    **animals_datasets,\n",
        "    train_test_split=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "import webbrowser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# submit the pipeline job\n",
        "train_test_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    train_test_pipeline,\n",
        "    # Project's name\n",
        "    experiment_name=\"image_preprocessing_pipeline\",\n",
        ")\n",
        "# open the pipeline in web browser\n",
        "webbrowser.open(train_test_pipeline_job.studio_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check out how the pipeline looks now, we only take the \"resized\" parts, not the rest of the components, which already happened before. Later on, we will combine them of course!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will quickly go over the following steps, because they are basically the same all over again.\n",
        "- Create a component script\n",
        "- Register the component in Azure\n",
        "- Register an Environment if needed\n",
        "- Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "training_src_dir = \"./components/training\"\n",
        "os.makedirs(training_src_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment with name aml-Tensorflow-Pillow is registered to workspace, the environment version is 1\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "\n",
        "custom_env_name = \"aml-Tensorflow-Pillow\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for AI Training (with Pillow)\",\n",
        "    tags={\"Pillow\": \"0.0.1\", \"Tensorflow\": \"2.4.1\"},\n",
        "    conda_file=os.path.join(\"components\", \"training\", \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./components/training/train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {training_src_dir}/train.py\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "from glob import glob\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "# This time we will need our Tensorflow Keras libraries, as we will be working with the AI training now\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# This AzureML package will allow to log our metrics etc.\n",
        "from azureml.core import Run\n",
        "\n",
        "# Important to load in the utils as well!\n",
        "from utils import *\n",
        "\n",
        "\n",
        "### HARDCODED VARIABLES FOR NOW\n",
        "### TODO for the students:\n",
        "### Make sure to adapt the ArgumentParser on line 31 to include these parameters\n",
        "### You can base your answer on the lines that are already there\n",
        "\n",
        "SEED = 42\n",
        "INITIAL_LEARNING_RATE = 0.01\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 11\n",
        "model_name = 'animal-cnn-test'\n",
        "\n",
        "def main():\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--training_folder', type=str, dest='training_folder', help='training folder mounting point')\n",
        "    parser.add_argument('--testing_folder', type=str, dest='testing_folder', help='testing folder mounting point')\n",
        "    parser.add_argument('--output_folder', type=str, dest='output_folder', help='Output folder')\n",
        "    parser.add_argument('--epochs', type=int, dest='epochs', help='The amount of Epochs to train')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    training_folder = args.training_folder\n",
        "    print('Training folder:', training_folder)\n",
        "\n",
        "    testing_folder = args.testing_folder\n",
        "    print('Testing folder:', testing_folder)\n",
        "\n",
        "    output_folder = args.output_folder\n",
        "    print('Testing folder:', output_folder)\n",
        "\n",
        "    MAX_EPOCHS = args.epochs\n",
        "\n",
        "    # As we're mounting the training_folder and testing_folder onto the `/mnt/data` directories, we can load in the images by using glob.\n",
        "    training_paths = glob(training_folder + \"/*.jpg\", recursive=True)\n",
        "    testing_paths = glob(testing_folder + \"/*.jpg\", recursive=True)\n",
        "\n",
        "    print(\"Training samples:\", len(training_paths))\n",
        "    print(\"Testing samples:\", len(testing_paths))\n",
        "\n",
        "    # Make sure to shuffle in the same way as I'm doing everything\n",
        "    random.seed(SEED)\n",
        "    random.shuffle(training_paths)\n",
        "    random.seed(SEED)\n",
        "    random.shuffle(testing_paths)\n",
        "\n",
        "    print(training_paths[:3]) # Examples\n",
        "    print(testing_paths[:3]) # Examples\n",
        "\n",
        "    # Parse to Features and Targets for both Training and Testing. Refer to the Utils package for more information\n",
        "    X_train = getFeatures(training_paths)\n",
        "    y_train = getTargets(training_paths)\n",
        "\n",
        "    X_test = getFeatures(testing_paths)\n",
        "    y_test = getTargets(testing_paths)\n",
        "\n",
        "    print('Shapes:')\n",
        "    print(X_train.shape)\n",
        "    print(X_test.shape)\n",
        "    print(len(y_train))\n",
        "    print(len(y_test))\n",
        "\n",
        "    # Make sure the data is one-hot-encoded\n",
        "    LABELS, y_train, y_test = encodeLabels(y_train, y_test)\n",
        "    print('One Hot Shapes:')\n",
        "\n",
        "    print(y_train.shape)\n",
        "    print(y_test.shape)\n",
        "\n",
        "    # Create an output directory where our AI model will be saved to.\n",
        "    # Everything inside the `outputs` directory will be logged and kept aside for later usage.\n",
        "    model_path = os.path.join(output_folder, model_name)\n",
        "    os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "\n",
        "    # Save the best model, not the last\n",
        "    cb_save_best_model = keras.callbacks.ModelCheckpoint(filepath=model_path,\n",
        "                                                            monitor='val_loss', \n",
        "                                                            save_best_only=True, \n",
        "                                                            verbose=1)\n",
        "\n",
        "    # Early stop when the val_los isn't improving for PATIENCE epochs\n",
        "    cb_early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                                patience= PATIENCE,\n",
        "                                                verbose=1,\n",
        "                                                restore_best_weights=True)\n",
        "\n",
        "    # Reduce the Learning Rate when not learning more for 4 epochs.\n",
        "    cb_reduce_lr_on_plateau = keras.callbacks.ReduceLROnPlateau(factor=.5, patience=4, verbose=1)\n",
        "\n",
        "    opt = tf.keras.optimizers.legacy.SGD(lr=INITIAL_LEARNING_RATE, decay=INITIAL_LEARNING_RATE / MAX_EPOCHS) # Define the Optimizer\n",
        "\n",
        "    model = buildModel((64, 64, 3), 3) # Create the AI model as defined in the utils script.\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "    # Construct & initialize the image data generator for data augmentation\n",
        "    # Image augmentation allows us to construct “additional” training data from our existing training data \n",
        "    # by randomly rotating, shifting, shearing, zooming, and flipping. This is to avoid overfitting.\n",
        "    # It also allows us to fit AI models using a Generator, so we don't need to capture the whole dataset in memory at once.\n",
        "    aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
        "                            height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "                            horizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "\n",
        "    # train the network\n",
        "    history = model.fit( aug.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
        "                            validation_data=(X_test, y_test),\n",
        "                            steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
        "                            epochs=MAX_EPOCHS,\n",
        "                            callbacks=[cb_save_best_model, cb_early_stop, cb_reduce_lr_on_plateau] )\n",
        "\n",
        "    print(\"[INFO] evaluating network...\")\n",
        "    predictions = model.predict(X_test, batch_size=32)\n",
        "    print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=['cats', 'dogs', 'panda'])) # Give the target names to easier refer to them.\n",
        "    # If you want, you can enter the target names as a parameter as well, in case you ever adapt your AI model to more animals.\n",
        "\n",
        "    cf_matrix = confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
        "    print(cf_matrix)\n",
        "\n",
        "    ### TODO for students\n",
        "    ### Find a way to log more information to the Run context.\n",
        "\n",
        "    # Save the confusion matrix to the outputs.\n",
        "    np.save(os.path.join(output_folder, '/confusion_matrix.npy'), cf_matrix)\n",
        "\n",
        "    print(\"DONE TRAINING\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "training_component = command(\n",
        "    name=\"training\",\n",
        "    display_name=\"Training an AI model\",\n",
        "    description=\"Trains an AI model by inputting a lot of training and testing data.\",\n",
        "    inputs={\n",
        "        \"training_folder\": Input(type=\"uri_folder\"),\n",
        "        \"testing_folder\": Input(type=\"uri_folder\"),\n",
        "        \"epochs\": Input(type=\"number\") # The percentage of the data to use as testing data, always a positive value\n",
        "    },\n",
        "    outputs={\n",
        "        \"output_folder\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    },\n",
        "    # The source folder of the component\n",
        "    code=training_src_dir,\n",
        "    command=\"\"\"python train.py \\\n",
        "            --training_folder ${{inputs.training_folder}} \\\n",
        "            --testing_folder ${{inputs.testing_folder}} \\\n",
        "            --output_folder ${{outputs.output_folder}} \\\n",
        "            --epochs ${{inputs.epochs}} \\\n",
        "            \"\"\",\n",
        "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading training (0.01 MBs): 100%|██████████| 10145/10145 [00:00<00:00, 62575.13it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component training with Version 2023-06-12-16-37-56-0745577 is registered\n"
          ]
        }
      ],
      "source": [
        "# Now we register the component to the workspace\n",
        "training_component = ml_client.create_or_update(training_component.component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(\n",
        "    f\"Component {training_component.name} with Version {training_component.version} is registered\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=cpu_compute_target,\n",
        "    description=\"Custom Animals Training pipeline\",\n",
        ")\n",
        "def animals_training_pipeline(\n",
        "    training_folder: Input, # Currently we don't use these version numbers, but we will use them later on.\n",
        "    testing_folder: Input,\n",
        "    epochs: int,\n",
        "):\n",
        "\n",
        "    training_job = training_component(\n",
        "        training_folder=training_folder,\n",
        "        testing_folder=testing_folder,\n",
        "        epochs=epochs\n",
        "    )\n",
        "    \n",
        "    # Let Azure decide a unique place everytime\n",
        "    training_job.outputs.output_folder = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"output_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # a pipeline returns a dictionary of outputs\n",
        "    # keys will code for the pipeline output identifier\n",
        "    return {\n",
        "        \"output_data\": training_job.outputs.output_folder,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "\n",
        "# Woops, make sure to use the correct version number here!\n",
        "training_pipeline = animals_training_pipeline(\n",
        "    # Change these versions if you want to override the choices\n",
        "    training_folder=Input(type=\"uri_folder\", path=f\"azureml:training_data:3\"),\n",
        "    testing_folder=Input(type=\"uri_folder\", path=f\"azureml:testing_data:13\"),\n",
        "    epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import webbrowser\n",
        "# submit the pipeline job\n",
        "training_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    training_pipeline,\n",
        "    # Project's name\n",
        "    experiment_name=\"training_pipeline\",\n",
        ")\n",
        "# open the pipeline in web browser\n",
        "webbrowser.open(training_pipeline_job.studio_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This pipeline ends here, we will not be chaining everything together yet, we will do that in the next Stage, where we will execute things from the CLI."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "mlops",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "1489b69aef9188e253991a72f2c1dcab719183ba23071189a69ddf1bcdf6e734"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
